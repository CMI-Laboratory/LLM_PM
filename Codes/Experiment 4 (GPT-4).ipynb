{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from openai import OpenAI\n",
    "import seaborn as sns\n",
    "import pymssql\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from threading import Thread\n",
    "import functools\n",
    "from tableone import TableOne\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n",
    "from threading import Thread\n",
    "import functools\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "conn = pymssql.connect(host=, database=, charset=) # enter pymssql connection info\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # enter openai api key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28815afa",
   "metadata": {},
   "source": [
    "# simulated data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lognormal_parameters(b, c, percentile_indecimal):\n",
    "    # Calculate z-scores for 1% and 99%\n",
    "    z_percentile = norm.ppf(percentile_indecimal)\n",
    "\n",
    "\n",
    "    # The median of the lognormal is the exp of the mean (mu) of the underlying normal\n",
    "    mu = np.log(b)\n",
    "\n",
    "    # Use the equations derived from lognormal properties to solve for sigma\n",
    "    # a = exp(mu + z_1 * sigma) and c = exp(mu + z_99 * sigma)\n",
    "    sigma = (np.log(c) - mu) / z_percentile\n",
    "    a = np.exp(mu + norm.ppf(0.001) * sigma)\n",
    "    c = np.exp(mu + norm.ppf(0.999) * sigma)\n",
    "\n",
    "    return mu, sigma, a, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_median=50\n",
    "age_99p=90\n",
    "height_men_median=175\n",
    "height_men_99p=187\n",
    "height_women_median=163\n",
    "height_women_99p=175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92e08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#men\n",
    "targetsize=10000\n",
    "continuous_data_list=['age','height_men']\n",
    "df_synthetic=pd.DataFrame()\n",
    "for i in range(len(continuous_data_list)):\n",
    "    totalsize=100000\n",
    "    if continuous_data_list[i]!='HDL':\n",
    "        percentilenum=0.99\n",
    "        percentilestr='99'\n",
    "    else:\n",
    "        percentilenum=0.01\n",
    "        percentilestr='1'\n",
    "        \n",
    "    b=globals()[   (continuous_data_list[i]+'_median'  )  ]\n",
    "    c=globals()[   (continuous_data_list[i]+'_'+percentilestr+  'p'  )  ]\n",
    "    x1,x2,p1,p99=find_lognormal_parameters(b, c,percentilenum)\n",
    "    \n",
    "    s = np.random.lognormal(x1, x2, totalsize)\n",
    "    s2=[]\n",
    "    for j in s:\n",
    "        if j<=p99 and j>=p1:\n",
    "            s2.append(j)\n",
    "    if len(s2)<targetsize:\n",
    "        print('===========error==============',continuous_data_list[i])\n",
    "    s2=s2[:targetsize]\n",
    "    df_synthetic[continuous_data_list[i]]=s2\n",
    "\n",
    "blacklist=[]\n",
    "\n",
    "for i in range(targetsize//2):\n",
    "    blacklist.append(0)\n",
    "for i in range(targetsize//2,targetsize):\n",
    "    blacklist.append(1)\n",
    "     \n",
    "random.shuffle(blacklist)  \n",
    "\n",
    "df_synthetic['black']=blacklist\n",
    "df_synthetic['sex']=1\n",
    "df_synthetic.columns=['age','height','black','sex']\n",
    "df_synthetic_men=df_synthetic.copy()\n",
    "plt.hist(df_synthetic_men['height'],bins=40)\n",
    "plt.show()\n",
    "\n",
    "#women\n",
    "targetsize=10000\n",
    "continuous_data_list=['age','height_women']\n",
    "df_synthetic=pd.DataFrame()\n",
    "for i in range(len(continuous_data_list)):\n",
    "    totalsize=100000\n",
    "    if continuous_data_list[i]!='HDL':\n",
    "        percentilenum=0.99\n",
    "        percentilestr='99'\n",
    "    else:\n",
    "        percentilenum=0.01\n",
    "        percentilestr='1'\n",
    "        \n",
    "    b=globals()[   (continuous_data_list[i]+'_median'  )  ]\n",
    "    c=globals()[   (continuous_data_list[i]+'_'+percentilestr+  'p'  )  ]\n",
    "    x1,x2,p1,p99=find_lognormal_parameters(b, c,percentilenum)\n",
    "    \n",
    "    s = np.random.lognormal(x1, x2, totalsize)\n",
    "    s2=[]\n",
    "    for j in s:\n",
    "        if j<=p99 and j>=p1:\n",
    "            s2.append(j)\n",
    "    if len(s2)<targetsize:\n",
    "        print('===========error==============',continuous_data_list[i])\n",
    "    s2=s2[:targetsize]\n",
    "    df_synthetic[continuous_data_list[i]]=s2\n",
    "\n",
    "blacklist=[]\n",
    "\n",
    "for i in range(targetsize//2):\n",
    "    blacklist.append(0)\n",
    "for i in range(targetsize//2,targetsize):\n",
    "    blacklist.append(1)\n",
    "     \n",
    "random.shuffle(blacklist)  \n",
    "\n",
    "df_synthetic['black']=blacklist\n",
    "df_synthetic['sex']=0\n",
    "df_synthetic.columns=['age','height','black','sex']\n",
    "df_synthetic_women=df_synthetic.copy()\n",
    "plt.hist(df_synthetic_women['height'],bins=40)\n",
    "plt.show()\n",
    "\n",
    "df_synthetic=pd.concat([df_synthetic_men,df_synthetic_women])\n",
    "df_synthetic.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86228c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_df=df_synthetic\n",
    "\n",
    "txtlist=[]\n",
    "for i in range(len(rand_df)):\n",
    "    txt = ''\n",
    "    txt += str(int(round(rand_df['age'][i],0)))\n",
    "    txt += ' year old '\n",
    "    \n",
    "    if rand_df['black'][i]==1:\n",
    "        txt += 'black '\n",
    "    else:\n",
    "        txt += 'white '\n",
    "    \n",
    "    if rand_df['sex'][i]==1:\n",
    "        txt += 'male, '\n",
    "    else:\n",
    "        txt += 'female, '\n",
    "\n",
    "    \n",
    "    txt += 'height '\n",
    "    txt += str(round(rand_df['height'][i],1))\n",
    "    txt += ' cm'\n",
    "\n",
    "    txtlist.append(txt)\n",
    "    \n",
    "rand_df['input_text']=txtlist\n",
    "\n",
    "rand_df['age']= round(rand_df['age'], 0)\n",
    "rand_df['height']= round(rand_df['height'], 1)\n",
    "\n",
    "rand_df['eid']=list(rand_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749932d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ebfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_df.to_csv('20241023_FVC_synthetic_20000.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1e08a",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580eee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rand_df=pd.read_csv('20241023_FVC_synthetic_20000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef212e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_df['input_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "usercontent_global1='''Estimate Forced Vital Capacity (FVC) for the person below.\n",
    "\n",
    "'''\n",
    "usercontent_global2='''\n",
    "\n",
    "Please answer exactly in the format below, without blank lines, and no further information or answer is required.\n",
    "FVC=(in liters, round to two decimal places)'''\n",
    "\n",
    "input_text=rand_df['input_text']\n",
    "eid=rand_df['eid']\n",
    "\n",
    "def timeout(timeout):\n",
    "    def deco(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            res = [Exception('function [%s] timeout [%s seconds] exceeded!' % (func.__name__, timeout))]\n",
    "            def newFunc():\n",
    "                try:\n",
    "                    res[0] = func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    res[0] = e\n",
    "            t = Thread(target=newFunc)\n",
    "            t.daemon = True\n",
    "            try:\n",
    "                t.start()\n",
    "                t.join(timeout)\n",
    "            except Exception as je:\n",
    "                print ('error starting thread')\n",
    "                raise je\n",
    "            ret = res[0]\n",
    "            #if isinstance(ret, BaseException):\n",
    "            #    raise ret\n",
    "            return ret\n",
    "        return wrapper\n",
    "    return deco\n",
    "\n",
    "@timeout(0.1)\n",
    "def ChatGPT_main(i,temper,responsenum):\n",
    "    if input_text[i]!='':\n",
    "        try:\n",
    "            usercontent=usercontent_global1\n",
    "            usercontent+=input_text[i]\n",
    "            usercontent+=usercontent_global2\n",
    "\n",
    "            messages=[\n",
    "                    #{\"role\": \"system\", \"content\": usercontent_global3},\n",
    "                    {\"role\": \"user\", \"content\": usercontent}\n",
    "                ]\n",
    "\n",
    "            client = OpenAI()\n",
    "            completion=client.chat.completions.create(\n",
    "                model='gpt-4',\n",
    "                n=responsenum,\n",
    "                temperature=temper,\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            \n",
    "            aa2=completion.choices\n",
    "            for j in range(len(aa2)):\n",
    "                aa=aa2[j].message.content.split('\\n')\n",
    "            #print(aa)\n",
    "                remove_set={''}\n",
    "                aaa=[ii for ii in aa if ii not in remove_set]\n",
    "\n",
    "                temp1='blank'\n",
    "                temp2=aaa[0].split('=')[1]\n",
    "                temp3='blank'\n",
    "                temp4='blank'\n",
    "                temp5='blank'\n",
    "                \n",
    "               conn = pymssql.connect(host=, database=, charset=) # enter pymssql connection info\n",
    "                with conn:\n",
    "                    with conn.cursor() as cur:\n",
    "                        cur.execute(sql, (str(eid[i]),temp1,temp2,temp3,temp4,temp5))\n",
    "                        conn.commit()\n",
    "\n",
    "        except:\n",
    "            temp1=np.nan\n",
    "            temp2=np.nan\n",
    "            temp3=np.nan\n",
    "            temp4=np.nan\n",
    "            temp5=np.nan\n",
    "            \n",
    "    else:\n",
    "        temp1=np.nan\n",
    "        temp2=np.nan\n",
    "        temp3=np.nan\n",
    "        temp4=np.nan\n",
    "        temp5=np.nan\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6eafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=4\n",
    "temper=0.0\n",
    "time1=datetime.datetime.now()\n",
    "usercontent=usercontent_global1\n",
    "usercontent+=input_text[i]\n",
    "usercontent+=usercontent_global2\n",
    "\n",
    "messages=[\n",
    "        #{\"role\": \"system\", \"content\": usercontent_global3},\n",
    "        {\"role\": \"user\", \"content\": usercontent}\n",
    "    ]\n",
    "\n",
    "client = OpenAI()\n",
    "completion=client.chat.completions.create(\n",
    "    model='gpt-4',\n",
    "    n=1,\n",
    "    temperature=temper,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "aa2=completion.choices\n",
    "time2=datetime.datetime.now()\n",
    "print(time2-time1)\n",
    "#data_final_groupmean[data_final_groupmean['eid']==i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bed3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responsenumnumnum=1\n",
    "for experimentnum in range(1,2):\n",
    "    print('=========================================================')\n",
    "    print('experimentnum',experimentnum)\n",
    "    input_text=rand_df['input_text']\n",
    "    ############################\n",
    "    table_name=\"20241023_FVC1\"\n",
    "    iterations=1\n",
    "    upto=20000\n",
    "    ############################\n",
    "    for temper in [0.0]:\n",
    "        time1=datetime.datetime.now()\n",
    "        while True:\n",
    "            toggle=0\n",
    "            for i in range(iterations):   \n",
    "                newtablaname=table_name + '_' + str(int(experimentnum)) + '_' + str(i)\n",
    "                try:\n",
    "                    sql_createtable=\"CREATE TABLE [\" + newtablaname +\"\"\"] \n",
    "                    (\n",
    "                        eid    NVARCHAR(20),\n",
    "                        system    NVARCHAR(max),\n",
    "                        score      NVARCHAR(max),\n",
    "                        category     NVARCHAR(max) ,\n",
    "                        framingham  NVARCHAR(20),\n",
    "                        ACC_AHA  NVARCHAR(20)\n",
    "                    )\n",
    "\n",
    "                    \"\"\"\n",
    "                    conn = pymssql.connect(host=, database=, charset=) # enter pymssql connection info\n",
    "                    with conn:\n",
    "                        with conn.cursor() as cur:\n",
    "                            cur.execute(sql_createtable)\n",
    "                            conn.commit()\n",
    "                    time.sleep(1)  \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                sql_statement=\"select * from [\"+ newtablaname + \"]\"\n",
    "                conn = pymssql.connect(host=, database=, charset=) # enter pymssql connection info\n",
    "                datasql = pd.read_sql(sql=sql_statement, con=conn)\n",
    "                datasql=datasql.astype({'eid':int})\n",
    "                cnt_df=datasql.groupby('eid')['score'].count()\n",
    "                tempcount=0\n",
    "                for j in range(upto):\n",
    "                    try:\n",
    "                        cnt=cnt_df[j]\n",
    "                        if cnt<responsenumnumnum:\n",
    "                            addcnt=int(responsenumnumnum-cnt)\n",
    "                            sql = \"INSERT INTO [\" + newtablaname+\"] (eid, system,score,category,framingham,ACC_AHA) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                            ChatGPT_main(j,temper,addcnt)\n",
    "                            tempcount+=1\n",
    "\n",
    "                    except:\n",
    "                        sql = \"INSERT INTO [\" + newtablaname+\"] (eid, system,score,category,framingham,ACC_AHA) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                        ChatGPT_main(j,temper,responsenumnumnum)\n",
    "                        tempcount+=1\n",
    "                    if j%100==0:\n",
    "                        print(j)\n",
    "\n",
    "                if tempcount==0:\n",
    "                    toggle=1\n",
    "            if toggle==1:\n",
    "                break\n",
    "            time.sleep(20)\n",
    "\n",
    "        time.sleep(20)\n",
    "\n",
    "\n",
    "        time2=datetime.datetime.now()\n",
    "        print(time2-time1)\n",
    "        #print('except_else_num = ',except_else_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f0f19",
   "metadata": {},
   "source": [
    "# UKB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b09fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt_cindex=[]\n",
    "validnum=[]\n",
    "for experimentnum in range(1,2):\n",
    "    print('=========================================================')\n",
    "    print('experimentnum',experimentnum)\n",
    "    rand_df=pd.read_csv('20241023_FVC_synthetic_20000.csv')\n",
    "    rand_df['eid']=range(20000)\n",
    "    input_text=rand_df['input_text']\n",
    "    ############################\n",
    "    table_name=\"20241023_FVC1\"\n",
    "    iterations=1\n",
    "    upto=20000\n",
    "    ############################\n",
    "    resultsdf=pd.DataFrame(columns=['validnum','age', 'HDL', 'LDL', 'TG', 'HbA1c', 'Cr', 'Urate', 'CRP', 'SBP', 'DBP', 'BMI', 'WHratio', 'sex', 'HTN', 'DM', 'Dyslipidemia', 'Afib', 'CKD', 'CVDfamily', 'smoking','avg_gpt_score','c-index gpt','c-index acc/aha','c-index framingham'])\n",
    "\n",
    "\n",
    "    for temper in [0.0]:\n",
    "        templist=[]\n",
    "        print('=========temperature========',temper)\n",
    "        for i in range(iterations):\n",
    "            newtablename=table_name + '_' + str(int(experimentnum)) + '_' + str(i)\n",
    "\n",
    "            sql_statement=\"select * from [\"+ newtablename + \"]\"\n",
    "            conn = pymssql.connect(host=, database=, charset=) # enter pymssql connection info\n",
    "            globals()['data{}'.format(i)] = pd.read_sql(sql=sql_statement, con=conn)\n",
    "\n",
    "\n",
    "        for j in range(iterations):\n",
    "            dat=globals()['data{}'.format(j)]\n",
    "\n",
    "            eid=dat['eid']\n",
    "            score_gpt=dat['score']\n",
    "            category=dat['category']\n",
    "            score_framingham=dat['framingham']\n",
    "            score_acc_aha=dat['ACC_AHA']\n",
    "\n",
    "            score_gpt2=[]\n",
    "\n",
    "            for i in range(len(score_gpt)):\n",
    "                try:\n",
    "                    score_gpt2.append(float(re.findall(\"\\d+[.]\\d+[%]\",score_gpt[i])[0].split('%')[0]))\n",
    "                except:\n",
    "                    try:\n",
    "                        score_gpt2.append(float(re.findall(\"\\d+[%]\",score_gpt[i])[0].split('%')[0]))\n",
    "                    except:\n",
    "                        try:\n",
    "                            score_gpt2.append(float(re.findall(\"\\d+[.]\\d+\",score_gpt[i])[0]))\n",
    "                        except:\n",
    "                            try:\n",
    "                                score_gpt2.append(float(re.findall(\"\\d+\",score_gpt[i])[-1]))\n",
    "                            except:\n",
    "                                score_gpt2.append(np.nan)\n",
    "                                #score_gpt2.append(float(score_framingham[i]))\n",
    "                                #print(score_gpt[i],'====')\n",
    "\n",
    "\n",
    "        data_final=pd.DataFrame({'eid':data0['eid'],'score':score_gpt2})\n",
    "        data_final['eid']=data_final['eid'].astype(int)\n",
    "        print(len(data_final))\n",
    "        data_final=data_final.dropna()\n",
    "        data_final.reset_index(inplace=True,drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final = data_final.groupby('eid')['score'].mean().reset_index()\n",
    "df_merged=pd.merge(data_final,rand_df,how='inner',on='eid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnslisttemp=list(df_merged.columns)\n",
    "columnslisttemp=columnslisttemp[2:]\n",
    "columnslisttemp=columnslisttemp[:-1]\n",
    "\n",
    "\n",
    "#print(columnslisttemp)\n",
    "#X=df_merged[['age','sex','HDL','LDL','TG','Chol','SBP','DBP','BMI','HTN','DM','smoking']]\n",
    "X=df_merged[columnslisttemp]\n",
    "y=df_merged['score']\n",
    "\n",
    "line_fitter = LinearRegression()\n",
    "line_fitter.fit(X, y)\n",
    "print(columnslisttemp)\n",
    "print(line_fitter.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=X.copy()\n",
    "X2['y']=y\n",
    "X2.to_csv('20241023_FVC_R.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnslisttemp=list(df_merged.columns)\n",
    "columnslisttemp=columnslisttemp[2:]\n",
    "columnslisttemp=columnslisttemp[:-1]\n",
    "\n",
    "\n",
    "#print(columnslisttemp)\n",
    "#X=df_merged[['age','sex','HDL','LDL','TG','Chol','SBP','DBP','BMI','HTN','DM','smoking']]\n",
    "df_merged_temp=df_merged[df_merged['sex']==1]\n",
    "\n",
    "X=df_merged_temp[columnslisttemp]\n",
    "X.drop(['sex'],inplace=True,axis=1)\n",
    "y=df_merged_temp['score']\n",
    "\n",
    "line_fitter = LinearRegression()\n",
    "line_fitter.fit(X, y)\n",
    "print(columnslisttemp)\n",
    "print(line_fitter.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe456778",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=X.copy()\n",
    "X2['y']=y\n",
    "X2.to_csv('20241023_FVC_R_male.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d873f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnslisttemp=list(df_merged.columns)\n",
    "columnslisttemp=columnslisttemp[2:]\n",
    "columnslisttemp=columnslisttemp[:-1]\n",
    "\n",
    "\n",
    "#print(columnslisttemp)\n",
    "#X=df_merged[['age','sex','HDL','LDL','TG','Chol','SBP','DBP','BMI','HTN','DM','smoking']]\n",
    "df_merged_temp=df_merged[df_merged['sex']==0]\n",
    "\n",
    "X=df_merged_temp[columnslisttemp]\n",
    "X.drop(['sex'],inplace=True,axis=1)\n",
    "y=df_merged_temp['score']\n",
    "\n",
    "line_fitter = LinearRegression()\n",
    "line_fitter.fit(X, y)\n",
    "print(columnslisttemp)\n",
    "print(line_fitter.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f762ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=X.copy()\n",
    "X2['y']=y\n",
    "X2.to_csv('20241023_FVC_R_female.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802ee92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx4090",
   "language": "python",
   "name": "rtx4090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
